{"cells":[{"cell_type":"markdown","source":["# Infuse Applications with AI Using IBM Watson OpenScale"],"metadata":{"collapsed":true}},{"cell_type":"markdown","source":["The following notebook is intended for use with the Watson OpenScale hands-on lab found [here](https://dtelink). It contains instructions and data for training and deploying an insurance fraud prediction model, and configuring Watson OpenScale to monitor and provide detailed explanations for that model's predictions.\n","\n","This notebook should be run in a Watson Studio project, using a Python 3.6 or above runtime environment. If you are viewing this in Watson Studio and do not see Python 3.6 or above in the upper right corner of your screen, please update the runtime now. It requires the following Cloud services:\n","\n","* __IBM Watson OpenScale__\n","* __Watson Machine Learning__\n","\n","If you have a paid Cloud account, you may also provision a __Databases for PostgreSQL__ or __Db2 Warehouse__ service to take full advantage of integration with Watson Studio and continuous learning services. If you choose not to provision this paid service, you can use the free internal PostgreSQL storage with OpenScale, but will not be able to configure continuous learning for your model."],"metadata":{}},{"cell_type":"markdown","source":["## Install packages"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import sklearn\n","import pandas as pd\n","from sklearn.ensemble import RandomForestClassifier\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from scipy.io import arff"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Provision services and configure credentials\n","\n","If you have not already, provision instances of [IBM Watson OpenScale](https://cloud.ibm.com/catalog/services/watson-openscale) and [Watson Machine Learning](https://cloud.ibm.com/catalog/services/machine-learning). The free lite versions of each plan will work for this tutorial.\n","\n","Your Cloud API key can be generated by going to the [__Users__ section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the __API Keys__ section, and click __Create an IBM Cloud API key__. Give your key a name and click __Create__, then copy the created key and paste it between the single quotes in the cell below."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["CLOUD_API_KEY = '___PASTE_API_KEY_HERE____'"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["WML_CREDENTIALS = {\n","    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n","    \"apikey\": CLOUD_API_KEY\n","}"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Create a deployment space\n","\n","All deployed models require a deployment space. Go to the [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=cpdaas) to create a new space, or choose an existing one. Click on the name of the space, then go to the __Settings__ tab. Locate the __Space ID__ and then click the icon to copy the ID to your clipboard. Paste your space ID between the quotation marks below."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["SPACE_ID = '___PASTE_SPACE_ID_HERE___'"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Database Credentials\n","\n","This tutorial can use Databases for PostgreSQL, Db2 Warehouse, or a free internal version of PostgreSQL to create a datamart for OpenScale. The free internal version can be accessed via the OpenScale APIs, but you will be unable to access it using direct database queries.\n","\n","If you have previously configured OpenScale, it will use your existing datamart, and not interfere with any models you are currently monitoring. Do not update the cell below.\n","\n","If you do not have a paid Cloud account or would prefer not to provision this paid service, you may use the free internal PostgreSQL service with OpenScale. Do not update the cell below.\n","\n","To provision a new instance of Db2 Warehouse, locate [Db2 Warehouse in the Cloud catalog](https://cloud.ibm.com/catalog/services/db2-warehouse), give your service a name, and click __Create__. Once your instance is created, click the __Service Credentials__ link on the left side of the screen. Click the __New credential__ button, give your credentials a name, and click __Add__. Your new credentials can be accessed by clicking the __View credentials__ button. Copy and paste your Db2 Warehouse credentials into the cell below.\n","\n","To provision a new instance of Databases for PostgreSQL, locate [Databases for PostgreSQL](https://cloud.ibm.com/catalog/services/databases-for-postgresql) in the Cloud catalog, give your service a name, and click __Create__. Once your instance is created, click the __Service Credentials__ link on the left side of the screen. Click the __New credential__ button, give your credentials a name, and click __Add__. Your new credentials can be accessed by clicking the __View credentials__ button. Copy and paste your Databases for PostgreSQL credentials into the cell below."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["DB_CREDENTIALS = None"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Restart the kernel and run the notebook\n","\n","At this point, the notebook is ready to run. _You must restart the kernel via the kernel menu above_. You can either restart the kernel and run the cells one at a time, starting from the package installation, or click the __Kernel__ option above and select __Restart and Run All__ to run all the cells."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["MODEL_NAME = \"SKLearn Fraud Prediction\"\n","DEPLOYMENT_NAME = \"SKLearn Fraud Deployment\""],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### Connect to OpenScale"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n","from ibm_watson_openscale import APIClient\n","\n","service_credentials = {\n","    \"apikey\": CLOUD_API_KEY,\n","    \"url\": \"https://api.aiopenscale.cloud.ibm.com\"\n","}\n","\n","authenticator = IAMAuthenticator(apikey=service_credentials['apikey'])\n","\n","wos_client = APIClient(authenticator=authenticator)\n","wos_client.version"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### Delete any existing subscriptions to this model in OpenScale"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["subscriptions = wos_client.subscriptions.list().result.subscriptions\n","for subscription in subscriptions:\n","    if subscription.entity.asset.name == MODEL_NAME:\n","        print(\"Deleting existing subscription for model\", subscription.entity.asset.name)\n","        wos_client.subscriptions.delete(subscription.metadata.id)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### Get the training data from github"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!rm training_data.csv\n","!wget https://raw.githubusercontent.com/emartensibm/openscale_insurance/master/data/training_data.csv"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### Explore the data\n","\n","The training data contains information on auto insurance claims that may indicate a higher likelihood of fraudulent claims. In this case, we have a set of binary variables for the following:\n","* __SUSPICIOUS\\_CLAIM\\_TIME__: The claim was filed after too much time had elapsed following the incident\n","* __EXPIRED\\_LICENSE__: The person filing the claim did not have a valid drivers license at the time of the incident\n","* __LOW\\_MILES\\_AT\\_LOSS__: The vehicle's mileage at the time of loss was lower than expected\n","* __EXCESSIVE\\_CLAIM\\_AMOUNT__: The dollar amount claimed was higher than expected given the value of the vehicle\n","* __TOO\\_MANY\\_CLAIMS__: The person filing the claim has multiple claims outstanding\n","* __NO\\_POLICE__: No police report was filed for the loss incident"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["features = [\"SUSPICIOUS_CLAIM_TIME\", \"EXPIRED_LICENSE\", \"LOW_MILES_AT_LOSS\", \"EXCESSIVE_CLAIM_AMOUNT\", \"TOO_MANY_CLAIMS\", \"NO_POLICE\", \"FLAG_FOR_FRAUD_INV\"]\n","df_model = pd.read_csv('training_data.csv')\n","\n","df_model.drop([\"DRIVER_ID\", \"POLICY_ID\", \"CLAIM_ID\", \"HOUSEHOLD_ID\", \"ZIPCODE\"], axis=1, inplace=True)\n","\n","df_model[\"SUSPICIOUS_CLAIM_TIME\"] = df_model[\"SUSPICIOUS_CLAIM_TIME\"].astype(int)\n","df_model[\"EXPIRED_LICENSE\"] = df_model[\"EXPIRED_LICENSE\"].astype(int)\n","df_model[\"LOW_MILES_AT_LOSS\"] = df_model[\"LOW_MILES_AT_LOSS\"].astype(int)\n","df_model[\"EXCESSIVE_CLAIM_AMOUNT\"] = df_model[\"EXCESSIVE_CLAIM_AMOUNT\"].astype(int)\n","df_model[\"TOO_MANY_CLAIMS\"] = df_model[\"TOO_MANY_CLAIMS\"].astype(int)\n","df_model[\"NO_POLICE\"] = df_model[\"NO_POLICE\"].astype(int)\n","df_model[\"FLAG_FOR_FRAUD_INV\"] = df_model[\"FLAG_FOR_FRAUD_INV\"].astype(int)\n","\n","df_model.head()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Identify the training data columns and label columns, and set up a train/test split of 80/20."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["xVar = df_model[[\"SUSPICIOUS_CLAIM_TIME\", \"EXPIRED_LICENSE\", \"LOW_MILES_AT_LOSS\", \"EXCESSIVE_CLAIM_AMOUNT\", \"TOO_MANY_CLAIMS\", \"NO_POLICE\"]]\n","yVar = df_model[\"FLAG_FOR_FRAUD_INV\"]\n","\n","x_train, x_test, y_train, y_test = train_test_split(xVar, yVar, test_size=0.2)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Create a scikit-learn Random Forest Classifier and fit the training data."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["model = RandomForestClassifier(n_jobs=2, random_state=0)\n","model.fit(x_train, y_train)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Check the test data using the model. For this model, an output of 1 indicates likely fraud; an output of 0 indicates unlikely fraud."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["predict_result = model.predict(x_test)\n","pd.crosstab(y_test, predict_result, rownames = [\"Actual Result\"], colnames = [\"Predicted Result\"])"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Store the model in Watson Machine Learning\n","\n","In this section, the notebook uses the supplied Watson Machine Learning credentials to save the model to the WML instance. Previous versions of the model are removed so that the notebook can be run again, resetting all data for another demo."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from ibm_watson_machine_learning import APIClient\n","wml_client = APIClient(WML_CREDENTIALS)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["space_details = wml_client.spaces.list()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["wml_client.set.default_space(SPACE_ID)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["wml_client.repository.list_models()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["deployment_details = wml_client.deployments.get_details()\n","for deployment in deployment_details['resources']:\n","    deployment_id = deployment['metadata']['id']\n","    model_id = deployment['entity']['asset']['id']\n","    if deployment['entity']['name'] == DEPLOYMENT_NAME:\n","        model_id = deployment['entity']['asset']['id']\n","        print('Deleting deployment id', deployment_id)\n","        wml_client.deployments.delete(deployment_id)\n","        print('Deleting model id', model_id)\n","        wml_client.repository.delete(model_id)\n","wml_client.repository.list_models()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["sw_spec_id = wml_client.software_specifications.get_id_by_name('scikit-learn_0.20-py3.6')\n","metadata = {\n","    wml_client.repository.ModelMetaNames.NAME: MODEL_NAME,\n","    wml_client.repository.ModelMetaNames.TYPE: 'scikit-learn_0.20',\n","    wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: sw_spec_id,\n","}\n","\n","df_train = df_model.copy()\n","df_train.drop(\"FLAG_FOR_FRAUD_INV\", axis=1, inplace=True)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["df_train.head()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Name the columns\n","cols=[\"SUSPICIOUS_CLAIM_TIME\",\"EXPIRED_LICENSE\",\"LOW_MILES_AT_LOSS\",\"EXCESSIVE_CLAIM_AMOUNT\",\"TOO_MANY_CLAIMS\",\"NO_POLICE\"]\n","      \n","saved_model = wml_client.repository.store_model(model=model, meta_props=metadata, training_data=df_train,\\\n","                                                training_target=df_model['FLAG_FOR_FRAUD_INV'], feature_names=cols,\\\n","                                                label_column_names=[\"FLAG_FOR_FRAUD_INV\"] )\n","\n","saved_model"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Deploy the model\n","\n","In this section, the model is deployed as a web service."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["model_uid = saved_model['metadata']['id']\n","print(\"Deploying model\", model_uid)\n","\n","meta_props = {\n","    wml_client.deployments.ConfigurationMetaNames.NAME: DEPLOYMENT_NAME,\n","    wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n","}\n","\n","deployment = wml_client.deployments.create(artifact_uid=model_uid, meta_props=meta_props)\n","deployment_uid = wml_client.deployments.get_uid(deployment)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["The deployed model is available as a web service, and can be called via the scoring endpoint. Values are passed and predictions are returned as JSON objects."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["scoring_endpoint = deployment['entity']['status']['online_url']['url']\n","scoring_endpoint"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["scoring_payload = {wml_client.deployments.ScoringMetaNames.INPUT_DATA:\n","                   [\n","                       {\n","                           \"fields\": [\"SUSPICIOUS_CLAIM_TIME\", \"EXPIRED_LICENSE\", \"LOW_MILES_AT_LOSS\", \"EXCESSIVE_CLAIM_AMOUNT\", \"TOO_MANY_CLAIMS\", \"NO_POLICE\"],\n","                           \"values\": [[0,1,0,1,0,1]]\n","                       }\n","                    ]\n","                  }"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["predictions = wml_client.deployments.score(deployment_uid, scoring_payload)\n","print(predictions)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Configure OpenScale\n","\n","We will now configure Watson OpenScale to monitor the deployed model. When this step is finished, all data into and out of the model will be logged, and can be made available to our applications via the Python API. Additionally, we will have the ability to generate explanations for individual predictions."],"metadata":{}},{"cell_type":"markdown","source":["The code below creates the OpenScale datamart, a database in which OpenScale will store its data. If you have already set up OpenScale, it will use your existing datamart and not remove any previous data. If you specified Db2 Warehouse or Databases for PostgreSQL credentials above, it will use those credentials to create a datamart with that paid service. Finally, if you have not previously used OpenScale and did not supply credentials for a paid database service, it will create the datamart in a free, internal database. This internal database still allows access via the OpenScale APIs, but you cannot access it directly via database queries."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["wos_client.data_marts.show()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["data_marts = wos_client.data_marts.list().result.data_marts\n","if len(data_marts) == 0:\n","    if DB_CREDENTIALS is not None:\n","        if SCHEMA_NAME is None: \n","            print(\"Please specify the SCHEMA_NAME and rerun the cell\")\n","\n","        print(\"Setting up external datamart\")\n","        added_data_mart_result = wos_client.data_marts.add(\n","                background_mode=False,\n","                name=\"WOS Data Mart\",\n","                description=\"Data Mart created by WOS tutorial notebook\",\n","                database_configuration=DatabaseConfigurationRequest(\n","                  database_type=DatabaseType.POSTGRESQL,\n","                    credentials=PrimaryStorageCredentialsLong(\n","                        hostname=DB_CREDENTIALS[\"connection\"][\"postgres\"][\"hosts\"][0][\"hostname\"],\n","                        username=DB_CREDENTIALS[\"connection\"][\"postgres\"][\"authentication\"][\"username\"],\n","                        password=DB_CREDENTIALS[\"connection\"][\"postgres\"][\"authentication\"][\"password\"],\n","                        db=DB_CREDENTIALS[\"connection\"][\"postgres\"][\"database\"],\n","                        port=DB_CREDENTIALS[\"connection\"][\"postgres\"][\"hosts\"][0][\"port\"],\n","                        ssl=True,\n","                        sslmode=DB_CREDENTIALS[\"connection\"][\"postgres\"][\"query_options\"][\"sslmode\"],\n","                        certificate_base64=DB_CREDENTIALS[\"connection\"][\"postgres\"][\"certificate\"][\"certificate_base64\"]\n","                    ),\n","                    location=LocationSchemaName(\n","                        schema_name= SCHEMA_NAME\n","                    )\n","                )\n","             ).result\n","    else:\n","        print(\"Setting up internal datamart\")\n","        added_data_mart_result = wos_client.data_marts.add(\n","                background_mode=False,\n","                name=\"WOS Data Mart\",\n","                description=\"Data Mart created by WOS tutorial notebook\", \n","                internal_database = True).result\n","        \n","    data_mart_id = added_data_mart_result.metadata.id\n","    \n","else:\n","    data_mart_id=data_marts[0].metadata.id\n","    print(\"Using existing datamart {}\".format(data_mart_id))"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Multiple service providers for the same engine instance are avaiable in Watson OpenScale. To avoid multiple service providers of used WML instance in the tutorial notebook the following code deletes existing service provder(s) and then adds new one."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from ibm_watson_openscale.supporting_classes.enums import *\n","from ibm_watson_openscale.supporting_classes import *"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["wos_client.service_providers.show()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["service_providers = wos_client.service_providers.list().result.service_providers\n","for service_provider in service_providers:\n","    service_instance_name = service_provider.entity.name\n","    if service_instance_name == \"WML instance for OpenScale\":\n","        service_provider_id = service_provider.metadata.id\n","        wos_client.service_providers.delete(service_provider_id)\n","        print(\"Deleted existing service_provider for WML instance: {}\".format(service_provider_id))"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["added_service_provider_result = wos_client.service_providers.add(\n","        name=\"WML instance for OpenScale\",\n","        description=\"Created for OpenScale Insurance tutorial\",\n","        service_type=ServiceTypes.WATSON_MACHINE_LEARNING,\n","        deployment_space_id = SPACE_ID,\n","        operational_space_id = \"production\",\n","        credentials=WMLCredentialsCloud(\n","            apikey=CLOUD_API_KEY,\n","            url='https://us-south.ml.cloud.ibm.com',\n","            instance_id=None\n","        ),\n","        background_mode=False\n","    ).result\n","service_provider_id = added_service_provider_result.metadata.id"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["asset = Asset(\n","    name = \"SKLearn Fraud Prediction\",\n","    asset_id=model_uid,\n","    url=scoring_endpoint,\n","    asset_type=AssetTypes.MODEL,\n","    input_data_type=InputDataType.STRUCTURED,\n","    problem_type=ProblemType.BINARY_CLASSIFICATION\n",")\n","asset_deployment = AssetDeploymentRequest(\n","    deployment_id=deployment_uid,\n","    name=DEPLOYMENT_NAME,\n","    deployment_type=DeploymentTypes.ONLINE,\n","    url=scoring_endpoint\n",")\n","training_data_reference = TrainingDataReference(\n","    type=\"cos\",\n","    location=COSTrainingDataReferenceLocation(\n","        bucket='faststartlab-donotdelete-pr-nhfd4jnhlxgpc7',\n","        file_name='insurance_fraud_training_data.csv'\n","    ),\n","    connection=COSTrainingDataReferenceConnection.from_dict(\n","        {\n","            \"resource_instance_id\": \"crn:v1:bluemix:public:cloud-object-storage:global:a/7d8b3c34272c0980d973d3e40be9e9d2:2883ef10-23f1-4592-8582-2f2ef4973639::\",\n","            \"url\": \"https://s3.us.cloud-object-storage.appdomain.cloud\",\n","            \"api_key\": \"yqcPbWZ0AQPHleHVerrR4Wx5e9pymBdMgydbEra5zCif\",\n","            \"iam_url\": \"https://iam.bluemix.net/oidc/token\"\n","        }\n","    )\n",")\n","asset_properties_request = AssetPropertiesRequest(\n","    label_column=\"FLAG_FOR_FRAUD_INV\",\n","    probability_fields=[\"probability\"],\n","    prediction_field=\"prediction\",\n","    feature_fields=cols,\n","    categorical_fields=[],\n","    training_data_reference=training_data_reference\n",")"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["subscription_details = wos_client.subscriptions.add(\n","        data_mart_id=data_mart_id,\n","        service_provider_id=service_provider_id,\n","        asset=asset,\n","        deployment=asset_deployment,\n","        asset_properties=asset_properties_request).result\n","subscription_id = subscription_details.metadata.id\n","print(subscription_details)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import time\n","\n","time.sleep(5)\n","payload_data_set_id = None\n","payload_data_set_id = wos_client.data_sets.list(type=DataSetTypes.PAYLOAD_LOGGING, \n","                                                target_target_id=subscription_id, \n","                                                target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\n","if payload_data_set_id is None:\n","    print(\"Payload data set not found. Please check subscription status.\")\n","else:\n","    print(\"Payload data set id:\", payload_data_set_id)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["wos_client.data_sets.show()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["wos_client.subscriptions.show()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### Score the model so we can configure monitors\n","Now that the datamart and subscription have been created, we need to send some sample data to the model for scoring so that OpenScale can create the correct schema for the payload logging table that will store our prediction history. These two records will be the two that we use for explanations as well.\n","\n","Note that we specify a customer ID as metadata in the scoring request; this will allow us to tie the prediction and explanation to a particular customer, so we can retreive the explanation data easily."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["fields = [\"SUSPICIOUS_CLAIM_TIME\", \"EXPIRED_LICENSE\", \"LOW_MILES_AT_LOSS\", \"EXCESSIVE_CLAIM_AMOUNT\", \"TOO_MANY_CLAIMS\", \"NO_POLICE\"]\n","values = [[0,1,0,0,0,1]]\n","meta = {\n","    \"fields\": [\"customer_id\"],\n","    \"values\": [['A2018MV533']]\n","}\n","\n","payload_scoring = {\"input_data\": [{\"fields\": fields, \"values\": values, \"meta\": meta}]}\n","predictions = wml_client.deployments.score(deployment_uid, payload_scoring)\n","print(predictions)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["payload_scoring"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["fields = [\"SUSPICIOUS_CLAIM_TIME\", \"EXPIRED_LICENSE\", \"LOW_MILES_AT_LOSS\", \"EXCESSIVE_CLAIM_AMOUNT\", \"TOO_MANY_CLAIMS\", \"NO_POLICE\"]\n","values = [[0,0,0,1,1,0]]\n","meta = {\n","    \"fields\": [\"customer_id\"],\n","    \"values\": [['A2016CA740']]\n","}\n","\n","payload_scoring = {\"input_data\": [{\"fields\": fields, \"values\": values, \"meta\": meta}]}\n","predictions = wml_client.deployments.score(deployment_uid, payload_scoring)\n","print(predictions)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import uuid\n","from ibm_watson_openscale.supporting_classes.payload_record import PayloadRecord\n","time.sleep(5)\n","pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n","print(\"Number of records in the payload logging table: {}\".format(pl_records_count))"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### Enable quality monitoring\n","\n","Set the minimum feedback data size to 50, and the alert threshold to 70%."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["target = Target(\n","        target_type=TargetTypes.SUBSCRIPTION,\n","        target_id=subscription_id\n",")\n","parameters = {\n","    \"min_feedback_data_size\": 50,\n","    \"threshold\": 0.7\n","}\n","quality_monitor_details = wos_client.monitor_instances.create(\n","    data_mart_id=data_mart_id,\n","    background_mode=False,\n","    monitor_definition_id=wos_client.monitor_definitions.MONITORS.QUALITY.ID,\n","    target=target,\n","    parameters=parameters\n",").result"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["The next cell enables the explanation service in OpenScale."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["target = Target(\n","    target_type=TargetTypes.SUBSCRIPTION,\n","    target_id=subscription_id\n",")\n","parameters = {\n","    \"enabled\": True\n","}\n","explainability_details = wos_client.monitor_instances.create(\n","    data_mart_id=data_mart_id,\n","    background_mode=False,\n","    monitor_definition_id=wos_client.monitor_definitions.MONITORS.EXPLAINABILITY.ID,\n","    target=target,\n","    parameters=parameters\n",").result\n","\n","explainability_monitor_id = explainability_details.metadata.id"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["The next two cells call the explanation service on our transactions, using the scoring IDs we provided. It should take between 30-60 seconds for each explanation to run. They can be run in background mode, but in this case we choose not to so the results can be displayed in the notebook.\n","\n","Once the explanation service has evaluated a prediction, the data is saved in the OpenScale datamart and can be accessed without re-running the service."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["records = wos_client.data_sets.get_list_of_records(data_set_id=payload_data_set_id, offset=0).result\n","scoring_ids = []\n","customer_ids = ['A2016CA740','A2018MV533']\n","for customer in customer_ids:\n","    for record in records['records']:\n","        if record[\"entity\"][\"values\"][\"customer_id\"] == customer:\n","            scoring_ids.append(record[\"entity\"][\"values\"][\"scoring_id\"])\n","            break\n","print(scoring_ids)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["print(\"Running explanations on scoring IDs: {}\".format(scoring_ids))\n","explanation_types = [\"lime\", \"contrastive\"]\n","result = wos_client.monitor_instances.explanation_tasks(scoring_ids=scoring_ids, explanation_types=explanation_types).result\n","print(result)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["task_id = result.metadata.explanation_task_ids[0]\n","task_id"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["task_state = 'in_progress'\n","while task_state == 'in_progress':\n","    explanation = wos_client.monitor_instances.get_explanation_tasks(task_id).result.to_dict()\n","    task_state = explanation['entity']['status']['state']\n","    if task_state == 'finished':\n","        break\n","    print(task_state)\n","    time.sleep(8)\n","explanation"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Next Steps\n","\n","Congratulations, you have successfully run the notebook. Please return to the tutorial for instructions on setting up the Flask web application that accesses the data created here and makes it available to usuers."],"metadata":{}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.6","language":"python"},"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"pycharm":{"stem_cell":{"cell_type":"raw","source":[],"metadata":{"collapsed":false}}}},"nbformat":4,"nbformat_minor":1}